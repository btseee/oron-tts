# OronTTS Model Configuration
# High-quality F5-TTS for Mongolian Khalkha Dialect

# Model Architecture
model:
  name: "oron-tts"
  type: "f5-tts"
  
  # DiT dimensions
  dim: 1024
  depth: 22
  num_heads: 16
  ff_mult: 4.0
  dropout: 0.1
  
  # Mel-spectrogram
  mel_dim: 100
  
  # Text/Phoneme
  phoneme_vocab_size: 256
  max_seq_len: 4096
  
  # Multi-speaker
  num_speakers: 128
  speaker_dim: 256
  
  # CFM
  sigma_min: 1.0e-4
  
  # Inference optimization
  use_flash_attn: true
  compile_model: true

# Audio Processing
audio:
  sample_rate: 24000
  n_fft: 1024
  hop_length: 256
  win_length: 1024
  n_mels: 100
  fmin: 0.0
  fmax: null  # Nyquist
  
  # DeepFilterNet for non-professional recordings
  # Disabled due to CUDA multiprocessing issues with DataLoader workers
  denoise: false
  denoise_atten_lim: 100.0
  
  # Normalization
  normalize_audio: true
  normalize_mel: true
  mel_mean: -4.0
  mel_std: 4.0

# Training
training:
  # Batch sizes (adjust based on GPU memory)
  batch_size: 4  # Reduced from 16 to fit in 24GB GPU
  gradient_accumulation_steps: 16  # Increased from 4 to maintain effective batch size of 64
  
  # Optimizer
  optimizer: "adamw"
  learning_rate: 5.0e-5
  weight_decay: 0.01
  betas: [0.9, 0.98]
  eps: 1.0e-9
  
  # Scheduler
  scheduler: "cosine"
  warmup_steps: 2000
  max_steps: 500000
  
  # Gradient clipping
  max_grad_norm: 1.0
  
  # Mixed precision
  mixed_precision: "bf16"
  
  # Checkpointing
  save_steps: 5000
  eval_steps: 2500
  max_checkpoints: 5
  
  # Logging
  log_steps: 50
  
  # EMA (Exponential Moving Average)
  use_ema: true
  ema_decay: 0.9999

# Inference
inference:
  cfg_scale: 2.5
  num_steps: 32  # More steps for quality
  method: "midpoint"

# Data
data:
  train_manifest: null  # Set via CLI
  val_manifest: null
  hf_dataset: null
  max_duration_sec: 30.0
  min_duration_sec: 0.5
  num_workers: 0  # Set to 0 to avoid espeak-ng library copying to /tmp
  pin_memory: true

# HuggingFace Hub
hub:
  repo_id: null  # Set via CLI
  private: true
  sync_checkpoints: true

# Advanced Options
advanced:
  # Gradient checkpointing for memory efficiency
  gradient_checkpointing: true
  
  # torch.compile options
  compile_mode: "reduce-overhead"
  
  # Data augmentation
  augment_speed: true
  speed_range: [0.9, 1.1]

hub:
  repo_id: "btseee/oron-tts"

