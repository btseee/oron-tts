# OronTTS RunPod Training Configuration - OPTIMIZED FOR RTX 4090
# Container: runpod/pytorch:2.4.0-py3.11-cuda12.4.1-devel-ubuntu22.04
# Hardware: RTX 4090 24GB VRAM, 21 vCPU, 41GB RAM

# Audio Settings
sample_rate: 22050
n_fft: 1024
hop_length: 256
win_length: 1024
n_mels: 80
fmin: 0.0
fmax: 8000.0

# Training Settings - MAXIMIZED FOR RTX 4090
batch_size: 18              # Increased from 12 - max VRAM utilization
num_epochs: 500             # Realistic for 3,846 samples
learning_rate: 0.0002       # Standard VITS learning rate
betas: [0.8, 0.99]
eps: 1.0e-8
lr_decay: 0.9995
segment_size: 64            # Doubled from 32 - better audio quality
fp16: true                  # ENABLED - 2x speedup on Ampere+ GPUs
num_workers: 16             # Increased from 8 - utilize all 21 vCPUs
log_interval: 50
save_interval: 5
grad_accumulation_steps: 1  # Disabled - batch_size now large enough
prefetch_factor: 4
pin_memory: true
use_tqdm: false

# Stability Settings
disc_warmup_steps: 2000
max_grad_norm: 1.0
grad_clip_value: 5.0        # Slightly increased for fp16

# Loss Weights - CRITICAL FIX (mel_loss × 25 in code)
# Effective: mel=25, kl=1.5, dur=1.0, fm=2.0, gen=1.0
loss_weight_mel: 1.0        # × 25 in losses.py
loss_weight_kl: 1.5         # CRITICAL - prevents encoder divergence
loss_weight_dur: 1.0
loss_weight_fm: 2.0
loss_weight_gen: 1.0

# CUDA Optimizations for RTX 4090
compile_model: false        # Stable baseline
cudnn_benchmark: true       # Auto-tune kernels
use_tf32: true              # TensorFloat-32 acceleration

# Model Architecture
model:
  inter_channels: 192
  hidden_channels: 192
  filter_channels: 768
  n_heads: 2
  n_layers: 6
  kernel_size: 3
  p_dropout: 0.1            # Standard dropout
  resblock: "1"
  resblock_kernel_sizes: [3, 7, 11]
  resblock_dilation_sizes: [[1, 3, 5], [1, 3, 5], [1, 3, 5]]
  upsample_rates: [8, 8, 2, 2]
  upsample_initial_channel: 512
  upsample_kernel_sizes: [16, 16, 4, 4]
  gin_channels: 256
  use_sdp: true

# Dataset Filtering
data:
  min_audio_length: 0.5
  max_audio_length: 15.0
  min_text_length: 2
  max_text_length: 500
